% -*- coding: utf-8; -*-
%%% Local Variables:
%%% mode: latex
%%% TeX-engine: xetex
%%% TeX-master: t
%%% End:
\documentclass[11pt]{scrartcl}
\usepackage[fancy, beaue, pset, anon]{sdll}
\pSet{\nt{MAT247}{V}{Invariant Subspaces}}
\usepackage{lineno}
% ----------------------------------------------------------------------
% Page setup
% ----------------------------------------------------------------------

\pagenumbering{gobble}

% ----------------------------------------------------------------------
% Custom commands
% ----------------------------------------------------------------------

% alignment

\newcommand*{\LongestHence}{$\Rightarrow$}% function name
\newcommand*{\LongestName}{$f_o(-x)+f_e(-x)$}% function name
\newcommand*{\LongestValue}{$(-a)x +(-a)(-y)$}% function value
\newcommand*{\LongestText}{\defi}%

\newlength{\LargestHenceSize}%
\newlength{\LargestNameSize}%
\newlength{\LargestValueSize}%
\newlength{\LargestTextSize}%

\settowidth{\LargestHenceSize}{\LongestHence}%
\settowidth{\LargestNameSize}{\LongestName}%
\settowidth{\LargestValueSize}{\LongestValue}%
\settowidth{\LargestTextSize}{\LongestText}%

% Choose alignment of the various elements here: [r], [l] or [c]

\newcommand*{\mbh}[1]{{\makebox[\LargestHenceSize][r]{\ensuremath{#1}}}}%
\newcommand*{\mbn}[1]{{\makebox[\LargestNameSize][r]{\ensuremath{#1}}}}%
\newcommand*{\mbv}[1]{\ensuremath{\makebox[\LargestValueSize][r]{\ensuremath{#1}}}}%
\newcommand*{\mbt}[1]{\makebox[\LargestTextSize][l]{#1}}%

\newcommand{\R}[1]{\label{#1}\linelabel{#1}}
\newcommand{\lr}[1]{line~\lineref{#1}}

% ----------------------------------------------------------------------
% Launch!
% ----------------------------------------------------------------------

\begin{document}
\section{Invariant Subspaces}
\begin{theorem}
  \label{sec:div}
  If $T\in \Hom(V,V)$ and $W\ssq V$ is $T$-invariant, then the
  characteristic polynomial of $T_{W}$, $f_w(t)$, divides the characteristic
  polynomial of $T$, $f(T)$.
\end{theorem}

\begin{proof}
  Pick an ordered basis $\alpha = \set{v_1, v_2, \dots, v_{d}}$ of $W$
  and extend it to an ordered basis $\beta=\set{v_1, \dots, v_n}$ of
  $V$.

  Then $[T]_{\beta} =
  \begin{pmatrix}
    [T_W]_{\alpha} &        & * \\
                   & \ddots &   \\
    0              &        & A
  \end{pmatrix}$.

  Note that
  \begin{align}
    f(t) &= \det([T]_{\beta} - t I)\\
         &= \det
  \begin{pmatrix}
    [T_W]_{\alpha} - t I_{W} &        & * \\
    & \ddots &   \\
    0              &        & A - t I_{A}
  \end{pmatrix}\\
         &= \det([T_W]_{\alpha} - t I)\det (A-tI) = f_W(t)\det(A-tI)
  \end{align}
                              
\end{proof}

\begin{theorem}
  Consider $T\in\Hom(V,V)$ and non-zero $v\in V$, where $V$ is a
  finite-dimensional vector space. Let $W$ be a $T$-cyclic subspace
  generated by $v$.

  Let $d \geq 1$ be the largest integer such that
  $v, T(v), \dots, T^{d-1}(v)$ are linearly independent. Then
  $v, T(v), \dots, T^{d-1}(v)$ is a basis of $W$ and $d = \dim W$.

\end{theorem}

\begin{proof}
  The largest $d$ exists, since $\dim V$ is finite.

  Let $U = \spn(v, T(v), \dots, T^{d-1}(v))\ssq W$.

  \begin{claim*}
    $U$ is $T$-invariant.
  \end{claim*}

  \begin{proof}
     $T(c_0v + c_1T(v)+\dots+c_{d-1}T^{d-1}(v)) = c_0Tv + c_1T^2v +\dots + c_{d-1}T^dv$

     Since $d$ is the largest integer such that
     $v, T(v), \dots, T^{d-1}(v)$ are linearly independent, then
     $c_{d-1}$ is non-zero, and thus $T^d(w) \in U$.
  \end{proof}

  $U$ is $T$-invariant, and thus if $v\in U$, then $W\ssq U$, since
  $W$ is the smallest $T-invariant$ subspace containing $v$. By
  definition of $U$, $U \ssq W$, and thus $U = W$.

\end{proof}

\begin{theorem}
  \label{sec:cycl}
  $T^d+a_{d-1}T^{d-1}v+\dots+a_1Tv+a_0v = 0$ and the characteristic polynomial of $T_{W}$ is

  \begin{equation*}
    f_W(t) = (-1)^d(t^d+a_{d-1}t^{d-1}+\dots+a_0)
  \end{equation*}
\end{theorem}

\begin{proof}
  Let $\beta = v, T(v), \dots, T^{d-1}(v)$.

  Then

  \begin{equation*}
    [T]_{\beta} = 
    \begin{pmatrix}
      0 & 0      & \dots  & 0      & -a_0   \\
      1 & 0      &        &        & -a_1   \\
      0 & 1      &        & \vdots & -a_2   \\
        & \ddots & \ddots &        & \vdots \\
        &        &        & 1      & -a_{d-1}
      \end{pmatrix}
    \end{equation*}

    Therefore, 
    \begin{equation*}
      \det ([T]_{\beta} -t I) = 
      \det\begin{pmatrix}
        -t & 0      & \dots  & 0      & -a_0   \\
        1  & -t     &        &        & -a_1   \\
        0  & 1      &        & \vdots & -a_2   \\
           & \ddots & \ddots &        & \vdots \\
           &        &        & 1      & -a_{d-1}-t
         \end{pmatrix}
    \end{equation*}

    Now we use induction on $d$.

    If $d=1$, $\det(-a_0-t) = -t-a_0 = (-1)(t+a_0)$.

    Suppose that the claim is true fr $d-1$. Consider the claim for $d$:

    \begin{align*}
      \det ([T]_{\beta} -t I) & = 
      \det\begin{pmatrix}
        -t                    & 0      & \dots  & 0      & -a_0   \\
        1                     & -t     &        &        & -a_1   \\
        0                     & 1      &        & \vdots & -a_2   \\
                              & \ddots & \ddots &        & \vdots \\
                              &        &        & 1      & -a_{d-1}-t
               \end{pmatrix}                                      \\
                              & =
      (-t)\det \begin{pmatrix}
        -t                    &        &        & -a_1            \\
        1                     &        & \vdots & -a_2            \\
        \ddots                & \ddots &        & \vdots          \\
                              &        & 1      & -a_{d-1}-t
             \end{pmatrix} + (-a_0)(-1)^{1+d}      \det\begin{pmatrix}
               1              & -t     &        &                 \\
               0              & 1      &        & \vdots          \\
                              & \ddots & \ddots &                 \\
                              &        &        & 1      
               \end{pmatrix}                                      \\
                              & = -(1)^{d}(t^{d}+a_{d-1}t^{d-1}+\dots +a_{1}t) + (-1)^{d}a_{0},
    \end{align*} 
    as required.
  \end{proof}

  \begin{example}

    \begin{align}
      T: \SP_3(\RR) & \to \SP_3(\RR) \\
      T(f(x))       & = xf'(x) - f(x)
    \end{align}

    If $f(x) = x^{3} - 1$, then
    \begin{align}
      T(f(x)) &= x(3x^{2}) - (x^3-1) = 2x^{3} +1\\
      T^{2}(f(x)) &= T(2x^3+1) = x (6x^2) - (2x^3+ 1) = 4x^3-1
    \end{align}

    Note that the first two are linearly independent, while all of
    three are linearly dependent.

    Therefore, the $T$-cyclic subspace $W$ generated by $f(x)$ has a
    basis $\set{x^3-1, 2x^3+1}$.

    So $T^2(f(x)) = 4x^3-1 = 4x^{3} -1 = 2f + 1T(f)$, giving the
    characteristic polynomial of $T_W$ as $t^2-t - 2$.
  \end{example}
\section{Cayley-Hamilton Theorem}
  \begin{theorem}[Cayley-Hamilton Theorem]
    Consider $T\in \Hom(V,V)$ with the characteristic polynomial
    $f(t)$. Then $f(T) = 0$.
  \end{theorem}

  \begin{description}
  \item[e.g.]  For the linear transfomation above, the Cayley-Hamilton
    Theorem says that \[T^2_W - T_{W} - 2I_{W} = 0\].
  \end{description}

  \begin{proof}
    We need to show that $f(T)v = 0$ for all $v\in V$.

    Note that  $f(T)$ is a linear transformation.

    If $v = 0$, $f(T)(0) = 0$.

    If $v \neq 0$, let $W$ be a $T$-cyclic subspace generated by $v$
    with the dimension $d = \dim W$.

    By Theorem \ref{sec:cycl}, if $v, Tv, \dots, T^{d-1}v$ is a basis
    of $W$, then 
    \begin{equation}
      \label{eq:1}
      T^{d}v + a_{d-1}T^{d-1}v + \dots +a_{0}v = 0
    \end{equation}
    and the characteristic polynomial $f_W(t)$ of $T_W$ is such as
    
    \begin{equation*}
      f_W(t) = (-1)^{d}(t^{d}+a_{d-1}t^{d-1} + \dots + a_{0})
    \end{equation*}.

    By Equation (\ref{eq:1}) we see that $f_{W}(T)(v) = 0$.

    By Theorem \ref{sec:div}, $f_{W}(T) | f(t)$, and thus $f(t) = g(t) f_{W}(t)$
    for some polynomial $g(t)$.

    Therefore, $f(T) = g(T)f_{W}(T)$, which gives
    \[f(T)(v) = (g(T)f_{W}(T))(v) = g(T)(f_{W}(T)(v)) = 0.\]
  \end{proof}
  \begin{remark}
    The Cayley-Hamilton Theorem can also be applied to matrices
    $A \in M_{n\times n}(\FF)$, which can be obtained by considering
    $T = L_{A}: \FF^n\to \FF^{n}$.
  \end{remark}
  \begin{theorem}
    Let $T\in \Hom(V, V)$ and $V = W_1\oplus \cdots \oplus W_{k}$,
    each subspace $W_{i}$ being $T$-invariant.  Then
    $f(T) = f_1(t) \cdots f_k(t)$, where $f(T)$ is a characteristic
    polynomial of $T$ and $f_i(T)$ is a characteristic polynomial of $T_{W_{i}}$.
  \end{theorem}
  \begin{proof}
    Pick an ordered basis $\beta_i$ of $W_i$ for $i=1, \dots, k$, and
    let $\beta = \beta_1\cup \cdots \cup \beta_{k}$. Since the sum of
    $W_{i}$ is direct, $\beta$ is a basis of $V$.

    Order $\beta$ canonically.

    Then

    \begin{align}
      [T]_{\beta} = 
      \begin{pmatrix}
        [T_{W_1}]_{\beta_1} & 0                   &        & \cdots & 0 \\
        0                   & [T_{W_2}]_{\beta_2} & 0      & \cdots & 0 \\
                            &                     & \ddots &        &   \\
        0                   &                     & \cdots &        & [T_{W_{k}}]_{\beta_{k}}
      \end{pmatrix}
    \end{align}


    Therefore,
    \begin{align}
      \det[T]_{\beta}                                                               & = 
                                              \det\begin{pmatrix}
                                                [T_{W_1}]_{\beta_1} - t I_{\beta_1} & 0                                   &        & \cdots & 0        \\
                                                0                                   & [T_{W_2}]_{\beta_2} - t I_{\beta_2} & 0      & \cdots & 0        \\
                                                                                    &                                     & \ddots &        &          \\
                                                0                                   & \cdots                              &        &        & [T_{W_{k}}]_{\beta_{k}} - t I_{\beta_k}
                                              \end{pmatrix}                                                                                            \\
                                                                                    & = \prod_{i=1}^{k}\det([T_{W_{i}}]_{\beta_{i}} - t I_{\beta_{i}}) \\
                                                                                    & 
                                                                                      =
                                                                                      \prod_{i=1}^{k}f_{i}(t)
    \end{align}
  \end{proof}
\end{document}